{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Importing required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "Collecting package metadata (current_repodata.json): done\n",
    "Solving environment: done\n",
    "\n",
    "\n",
    "==> WARNING: A newer version of conda exists. <==\n",
    "  current version: 23.3.1\n",
    "  latest version: 23.5.0\n",
    "\n",
    "Please update conda by running\n",
    "\n",
    "    $ conda update -n base -c defaults conda\n",
    "\n",
    "Or to minimize the number of packages updated during conda update use\n",
    "\n",
    "     conda install conda=23.5.0\n",
    "    \n",
    "\n",
    "# All requested packages already installed.\n",
    "\n",
    "\n",
    "Note: you may need to restart the kernel to use updated packages.\n",
    "\n",
    "## Importing required packages\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "def create_connection(path):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = sqlite3.connect(path)\n",
    "        print(\"Connection to SQLite DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection\n",
    "\n",
    "\n",
    "## Importing required packages\n",
    "## Creating a regression model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "##Generate some random data for demonstration\n",
    "X = np.array([[1], [2], [3], [4], [5]])  # Input features\n",
    "y = np.array([2, 4, 5, 4, 6])  # Target variable\n",
    "\n",
    "##Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "##Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "##Predict using the trained model\n",
    "X_new = np.array([[6]])  # New input for prediction\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "print(\"Predicted y:\", y_pred)\n",
    "\n",
    "## Creating a regression model\n",
    "\n",
    "## Importing required packages\n",
    "connection = create_connection(\"E:\\\\sm_app.sqlite\")\n",
    "Connection to SQLite DB successful\n",
    "\n",
    "## Checking how many variables we have\n",
    "print(df_NYC-BikeShare-2015-2017-combined.shape)\n",
    "\n",
    "## Checking column names + data times\n",
    "df_NYC-BikeShare-2015-2017-combined.dtypes\n",
    "\n",
    "## Checking for duplicates for Id\n",
    "idsUnique = len(set(df_NYC-BikeShare-2015-2017-combined.Id))\n",
    "idsTotal = df_NYC-BikeShare-2015-2017-combined.shape[0]\n",
    "idsdupe = idsTotal - idsUnique\n",
    "print(idsdupe)\n",
    "# drop id col\n",
    "df_NYC-BikeShare-2015-2017-combined.drop(['Id'],axis =1,inplace=True)\n",
    "\n",
    "# descriptive statistics\n",
    "df_NYC-BikeShare-2015-2017-combined['Bike Stations'].describe()\n",
    "# histogram\n",
    "sns.histplot(df_NYC-BikeShare-2015-2017-combined['Restaurants'])\n",
    "\n",
    "## Printing out lists of columns\n",
    "sorted(list(df_NYC-BikeShare-2015-2017-combined.columns))\n",
    "\n",
    "## scatter plot Start longitude vs. latitude\n",
    "var = 'Longitude'\n",
    "data = df_NYC-BikeShare-2015-2017-combined[['Latitude',var]]\n",
    "data.plot.scatter(x=var, y='StopTime', ylim=(0,800000))\n",
    "\n",
    "# overallqual\n",
    "var = 'Bikes'\n",
    "data = df_NYC-BikeShare-2015-2017-combined[['TripDuration',var]]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"TripDuration\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000)\n",
    "\n",
    "# Neighborhood\n",
    "var = 'Neighborhood'\n",
    "data = df_NYC-BikeShare-2015-2017-combined[['Bike Stations',var]]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"Restaurants\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Bike ID\n",
    "var = 'Restaurants'\n",
    "data = df_train[['Count',var]]\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=var, y=\"Restaurants\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# correlation matrix\n",
    "corrmat = df_NYC-BikeShare-2015-2017-combined.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True,cmap=\"RdYlGn_r\")\n",
    "\n",
    "# most correlated features with TripDuration\n",
    "corrmat = df_NYC-BikeShare-2015-2017-combined.corr()\n",
    "top_corr_features = corrmat.index[abs(corrmat[\"TripDuration\"])>0.5]\n",
    "plt.figure(figsize=(10,10))\n",
    "g = sns.heatmap(df_NYC-BikeShare-2015-2017-combined[top_corr_features].corr(),annot=True,cmap=\"RdYlGn_r\")\n",
    "\n",
    "## Intercept\n",
    "print(f\"intercept: {model.intercept_}\")\n",
    "intercept: 5.633333333333329\n",
    "    \n",
    "## Slope\n",
    "print(f\"slope: {model.coef_}\")\n",
    "\n",
    "## LinearRegression\n",
    "new_model = LinearRegression().fit(x, y.reshape((-1, 1)))\n",
    "print(f\"intercept: {new_model.intercept_}\")\n",
    "intercept: [5.63333333]\n",
    "\n",
    "## Slope\n",
    "print(f\"slope: {new_model.coef_}\")\n",
    "\n",
    "## Predictions\n",
    "y_pred = model.predict(x)\n",
    "print(f\"predicted response:\\n{y_pred}\")\n",
    "\n",
    "## Predictions\n",
    "y_pred = model.intercept_ + model.coef_ * x\n",
    "print(f\"predicted response:\\n{y_pred}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide model output and an interpretation of the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(array([33, 45, 28, 15,  1]),\n",
    " array([  4000.,  68000., 132000., 196000., 260000., 324000.]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you turn the regression model into a classification model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use discretised percentiles to define categories instead of numerical values\n",
    "\n",
    "# Letâ€™s calculate the numeric histogram from the actual test target\n",
    "hist, bin_edges = np.histogram(y_test, bins=5)\n",
    "hist, bin_edges\n",
    "\n",
    "# convert each y in training and test sets to a class\n",
    "y_train_distributive = [map_float_to_class(y) for y in y_train]\n",
    "y_test_distributive = [map_float_to_class(y) for y in y_test]\n",
    "\n",
    "# Import the classifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = XGBClassifier()\n",
    "# Train to get a label\n",
    "model.fit(X_train, y_train_distributive)\n",
    "# Get the labels\n",
    "predictions = model.predict(X_test)\n",
    "# How good does it work\n",
    "accuracy_score(y_test_distributive, predictions)\n",
    "# Output: 0.5327868852459017\n",
    "\n",
    "# Instead of the labels get the probability distributions\n",
    "predictions = model.predict_proba(X_test)\n",
    "\n",
    "# Plot some of the predicted trip durations\n",
    "fig, ax = plt.subplots(3, 3)\n",
    "fig.set_size_inches(16, 6)\n",
    "# Random indexes picked\n",
    "ax[0, 0].bar(labels, predictions[1])\n",
    "ax[0, 1].bar(labels, predictions[5])\n",
    "ax[0, 2].bar(labels, predictions[8])\n",
    "ax[1, 0].bar(labels, predictions[10])\n",
    "ax[1, 1].bar(labels, predictions[15])\n",
    "ax[1, 2].bar(labels, predictions[20])\n",
    "ax[2, 0].bar(labels, predictions[40])\n",
    "ax[2, 1].bar(labels, predictions[47])\n",
    "ax[2, 2].bar(labels, predictions[52])\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Some calculated distributions samples\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
